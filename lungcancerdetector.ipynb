{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39564303-3e31-4c28-9ddb-fb6f5bf4a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of: !pip install -q kaggle opencv-python-headless tensorflow matplotlib\n",
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kaggle\", \"opencv-python-headless\", \"tensorflow\", \"matplotlib\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd65d32-72dc-498f-9406-03c463dda247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of: !mkdir -p ~/.kaggle\n",
    "import os\n",
    "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f430a24-71e1-4bfe-9f0c-6feecdb2a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of: !cp kaggle.json ~/.kaggle/\n",
    "import shutil\n",
    "shutil.copy(\"kaggle.json\", os.path.expanduser(\"~/.kaggle/kaggle.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62948f-78f2-447c-974d-0c4cb148e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of: !chmod 600 ~/.kaggle/kaggle.json\n",
    "import os\n",
    "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeefd05-789d-4864-9edd-e1400dfa85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of: !kaggle datasets download -d andrewmvd/lung-and-colon-cancer-histopathological-images\n",
    "subprocess.check_call([\"kaggle\", \"datasets\", \"download\", \"-d\", \"andrewmvd/lung-and-colon-cancer-histopathological-images\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742818e-4d9f-4ddd-883c-bf6acbfed5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of: !unzip -o lung-and-colon-cancer-histopathological-images.zip -d lung_cancer_dataset > /dev/null\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"lung-and-colon-cancer-histopathological-images.zip\", \"r\") as zf:\n",
    "    zf.extractall(\"lung_cancer_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81230430-ab7e-4c87-8ca7-78d37cac16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of: !ls lung_cancer_dataset\n",
    "print(os.listdir(\"lung_cancer_dataset\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df2dd8e-e1d6-4571-9e5f-6e05d96303ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"  # show outputs of all statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fde439-27d5-4e68-aaf4-165623dafc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# Lung Cancer Classification (Jupyter v1)\n",
    "# =====================================\n",
    "\n",
    "# 0. Install dependencies (only run once, restart kernel after install)\n",
    "import sys, subprocess\n",
    "\n",
    "def install_if_missing(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        print(f\"âœ… {pkg} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"ðŸ“¦ Installing {pkg} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for p in [\"kaggle\", \"opencv-python-headless\", \"tensorflow\", \"matplotlib\"]:\n",
    "    install_if_missing(p)\n",
    "\n",
    "# 1. Imports\n",
    "import os, shutil, zipfile, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "print(\"âœ… TensorFlow:\", tf.__version__)\n",
    "\n",
    "# Make sure Jupyter shows all outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Kaggle Dataset Download\n",
    "# ------------------------------\n",
    "print(\"ðŸ“¥ Preparing Kaggle API...\")\n",
    "\n",
    "# Place kaggle.json in current folder before running\n",
    "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "shutil.copy(\"kaggle.json\", os.path.expanduser(\"~/.kaggle/kaggle.json\"))\n",
    "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)\n",
    "\n",
    "print(\"ðŸ“¥ Downloading dataset...\")\n",
    "subprocess.check_call([\"kaggle\", \"datasets\", \"download\", \"-d\",\n",
    "                       \"andrewmvd/lung-and-colon-cancer-histopathological-images\"])\n",
    "\n",
    "print(\"ðŸ“‚ Unzipping dataset...\")\n",
    "with zipfile.ZipFile(\"lung-and-colon-cancer-histopathological-images.zip\", \"r\") as zf:\n",
    "    zf.extractall(\"lung_cancer_dataset\")\n",
    "\n",
    "print(\"ðŸ“‘ Dataset structure:\")\n",
    "print(os.listdir(\"lung_cancer_dataset\"))\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Data Generators\n",
    "# ------------------------------\n",
    "train_dir = \"lung_cancer_dataset/train\"\n",
    "val_dir   = \"lung_cancer_dataset/val\"\n",
    "test_dir  = \"lung_cancer_dataset/test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen   = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=(224,224), batch_size=16, class_mode='binary'\n",
    ")\n",
    "val_gen   = val_datagen.flow_from_directory(\n",
    "    val_dir, target_size=(224,224), batch_size=16, class_mode='binary'\n",
    ")\n",
    "test_gen  = test_datagen.flow_from_directory(\n",
    "    test_dir, target_size=(224,224), batch_size=16, class_mode='binary', shuffle=False\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Model Setup (ResNet50)\n",
    "# ------------------------------\n",
    "print(\"ðŸ”§ Building ResNet50 model...\")\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=out)\n",
    "model.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Training (1 epoch only for debug)\n",
    "# ------------------------------\n",
    "print(\"ðŸš€ Training for 1 epoch...\")\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=1)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Evaluation\n",
    "# ------------------------------\n",
    "print(\"ðŸ“Š Evaluating on test set...\")\n",
    "loss, acc = model.evaluate(test_gen)\n",
    "print(f\"âœ… Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Grad-CAM\n",
    "# ------------------------------\n",
    "def get_last_conv_layer(model):\n",
    "    for layer in reversed(model.layers):\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            return layer.name\n",
    "    return None\n",
    "\n",
    "def gradcam(img_path, model):\n",
    "    last_conv = get_last_conv_layer(model)\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    arr = np.expand_dims(image.img_to_array(img)/255.0, axis=0)\n",
    "    \n",
    "    grad_model = tf.keras.models.Model([model.inputs], \n",
    "                                       [model.get_layer(last_conv).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_out, pred = grad_model(arr)\n",
    "        loss = pred[:,0]\n",
    "    grads = tape.gradient(loss, conv_out)[0]\n",
    "    pooled = tf.reduce_mean(grads, axis=(0,1))\n",
    "    conv_out = conv_out[0]\n",
    "    heatmap = np.dot(conv_out, pooled[..., tf.newaxis])\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap) + 1e-8\n",
    "    heatmap = cv2.resize(heatmap.numpy(), (224,224))\n",
    "    heatmap = np.uint8(255*heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    orig = cv2.imread(img_path)\n",
    "    orig = cv2.resize(orig, (224,224))\n",
    "    superimposed = cv2.addWeighted(orig, 0.6, heatmap, 0.4, 0)\n",
    "    return superimposed\n",
    "\n",
    "# pick one test image\n",
    "sample_class = os.listdir(test_dir)[0]\n",
    "sample_img = os.path.join(test_dir, sample_class, os.listdir(os.path.join(test_dir, sample_class))[0])\n",
    "print(\"ðŸ–¼ Sample image:\", sample_img)\n",
    "\n",
    "grad_img = gradcam(sample_img, model)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(grad_img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Grad-CAM Output\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82608eee-bf52-46df-bd81-e0b31c2da71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune learning rate + optimizer\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),   # instead of 1e-3\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Increase epochs + batch size tuning\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10,              # run longer\n",
    "    batch_size=32           # try 16 / 32 / 64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ab98f-4570-476b-8a7b-7bcce858a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze last 30 layers of ResNet50\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile with smaller LR (fine-tuning)\n",
    "model.compile(optimizer=Adam(1e-5), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fine-tune\n",
    "history_finetune = model.fit(train_gen, validation_data=val_gen, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60127e-c304-4df3-8233-18ad038f4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b7833-ba5c-453c-b43a-2231117bc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3),\n",
    "    ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=30, callbacks=callbacks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
